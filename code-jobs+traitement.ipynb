{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b1aaa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1640797683.py, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_1560\\1640797683.py\"\u001b[1;36m, line \u001b[1;32m56\u001b[0m\n\u001b[1;33m    time.sleep(3)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "# installation de driver \n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "\n",
    "# chargement de la page de login\n",
    "driver.get(\"https://www.linkedin.com/login\")\n",
    "\n",
    "\n",
    "\n",
    "# compte LinkedIn \n",
    "user_name = 'choukhantriikram@gmail.com'\n",
    "password = 'chtr20082001'\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"username\"))).send_keys(user_name)\n",
    "WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.ID, \"password\"))).send_keys(password)\n",
    "\n",
    "# boutton login         \n",
    "elements = driver.find_elements('xpath', '//*[@id=\"organic-div\"]/form/div[3]/button')\n",
    "elements[0].click()\n",
    "\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# page des jobs                          \n",
    "WebDriverWait(driver, 30).until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"global-nav\"]/div/nav/ul/li[3]/a'))).click()\n",
    "\n",
    "# page d'ou on va scapper \n",
    "driver.get(\"https://www.linkedin.com/jobs/search/?currentJobId=3324500841&geoId=102787409&keywords=business%20intelligence%20and%20analytics&location=Morocco&refresh=true\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get all links for these offers\n",
    "links = []\n",
    "# Navigate 13 pages\n",
    "print('Links are being collected now.')\n",
    "\n",
    "try: \n",
    "    for page in range(2,14):\n",
    "        time.sleep(2)\n",
    "        jobs_block = driver.find_element(By.CLASS_NAME, 'jobs-search-results-list')\n",
    "        jobs_list = jobs_block.find_elements(By.CSS_SELECTOR, '.jobs-search-results__list-item')\n",
    "    \n",
    "        for job in jobs_list:\n",
    "            all_links = job.find_elements(By.TAG_NAME, 'a')\n",
    "            for a in all_links:\n",
    "                if str(a.get_attribute('href')).startswith(\"https://www.linkedin.com/jobs/view\") and a.get_attribute('href') not in links: \n",
    "                    links.append(a.get_attribute('href'))\n",
    "            # scroll down for each job element\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", job)\n",
    "       \n",
    "        print(f'Collecting the links on page {page-1}')\n",
    "       # go to next page:\n",
    "        driver.find_element(By.XPATH, f\"//button[@aria-label='Page {page}']\").click()\n",
    "        time.sleep(3)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")                                     \n",
    "   \n",
    "    print('Found ' + str(len(links)) + ' links for job offers')\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63b7bed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.linkedin.com/jobs/view/3599036508/?eBP=JOB_SEARCH_ORGANIC&refId=IlUKUQdthOcaE9%2FhDd9ZVQ%3D%3D&trackingId=Thh4oKhfCtCsnKwLO4XHUg%3D%3D&trk=flagship3_search_srp_jobs', 'https://www.linkedin.com/jobs/view/3596291241/?eBP=JOB_SEARCH_ORGANIC&refId=IlUKUQdthOcaE9%2FhDd9ZVQ%3D%3D&trackingId=OAM%2Fa2FYs8WInBo6p2KI1Q%3D%3D&trk=flagship3_search_srp_jobs', 'https://www.linkedin.com/jobs/view/3608146573/?eBP=JOB_SEARCH_ORGANIC&refId=IlUKUQdthOcaE9%2FhDd9ZVQ%3D%3D&trackingId=Y7z2PnCOblB7CzNAR3xUvw%3D%3D&trk=flagship3_search_srp_jobs', 'https://www.linkedin.com/jobs/view/3552976177/?eBP=JOB_SEARCH_ORGANIC&refId=IlUKUQdthOcaE9%2FhDd9ZVQ%3D%3D&trackingId=H%2BiC7vWqGiUFCXb%2FeyOUZQ%3D%3D&trk=flagship3_search_srp_jobs', 'https://www.linkedin.com/jobs/view/3602570246/?eBP=JOB_SEARCH_ORGANIC&refId=IlUKUQdthOcaE9%2FhDd9ZVQ%3D%3D&trackingId=8iN1RU47FOIsnpiAwfzvbA%3D%3D&trk=flagship3_search_srp_jobs', 'https://www.linkedin.com/jobs/view/3610206071/?eBP=JOB_SEARCH_ORGANIC&refId=IlUKUQdthOcaE9%2FhDd9ZVQ%3D%3D&trackingId=CIGvjjKS9SvCT%2FzlMWD42A%3D%3D&trk=flagship3_search_srp_jobs', 'https://www.linkedin.com/jobs/view/3569956153/?eBP=JOB_SEARCH_ORGANIC&refId=IlUKUQdthOcaE9%2FhDd9ZVQ%3D%3D&trackingId=%2FuR9h8HjwF2lmxYNM42oVQ%3D%3D&trk=flagship3_search_srp_jobs', 'https://www.linkedin.com/jobs/view/3569958090/?eBP=JOB_SEARCH_ORGANIC&refId=IlUKUQdthOcaE9%2FhDd9ZVQ%3D%3D&trackingId=nyNczjQwitHUZzzy55a2SQ%3D%3D&trk=flagship3_search_srp_jobs']\n"
     ]
    }
   ],
   "source": [
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc31c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a2238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dcdb5e90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting the links and collecting information...\n",
      "Scraping job details: 1 DONE.\n",
      "Scraping the description of Job Offer 1\n",
      "Scraping job details: 2 DONE.\n",
      "Scraping the description of Job Offer 2\n",
      "Scraping job details: 3 DONE.\n",
      "Scraping the description of Job Offer 3\n",
      "Scraping job details: 4 DONE.\n",
      "Scraping the description of Job Offer 4\n",
      "Scraping job details: 5 DONE.\n",
      "Scraping the description of Job Offer 5\n",
      "Scraping job details: 6 DONE.\n",
      "Scraping the description of Job Offer 6\n",
      "Scraping job details: 7 DONE.\n",
      "Scraping the description of Job Offer 7\n",
      "Scraping job details: 8 DONE.\n",
      "Scraping the description of Job Offer 8\n",
      "Scraping job details: 9 DONE.\n",
      "Scraping the description of Job Offer 9\n",
      "Scraping job details: 10 DONE.\n",
      "Scraping the description of Job Offer 10\n",
      "Scraping job details: 11 DONE.\n",
      "Scraping the description of Job Offer 11\n",
      "Scraping job details: 12 DONE.\n",
      "Scraping the description of Job Offer 12\n",
      "Scraping job details: 13 DONE.\n",
      "Scraping the description of Job Offer 13\n",
      "Scraping job details: 14 DONE.\n",
      "Scraping the description of Job Offer 14\n",
      "Scraping job details: 15 DONE.\n",
      "Scraping the description of Job Offer 15\n",
      "Scraping job details: 16 DONE.\n",
      "Scraping the description of Job Offer 16\n",
      "Scraping job details: 17 DONE.\n",
      "Scraping the description of Job Offer 17\n",
      "Scraping job details: 18 DONE.\n",
      "Scraping the description of Job Offer 18\n",
      "Scraping job details: 19 DONE.\n",
      "Scraping the description of Job Offer 19\n",
      "Scraping job details: 20 DONE.\n",
      "Scraping the description of Job Offer 20\n",
      "Scraping job details: 21 DONE.\n",
      "Scraping the description of Job Offer 21\n",
      "Scraping job details: 22 DONE.\n",
      "Scraping the description of Job Offer 22\n",
      "Scraping job details: 23 DONE.\n",
      "Scraping the description of Job Offer 23\n",
      "Scraping job details: 24 DONE.\n",
      "Scraping the description of Job Offer 24\n",
      "Scraping job details: 25 DONE.\n",
      "Scraping the description of Job Offer 25\n",
      "Scraping job details: 26 DONE.\n",
      "Scraping the description of Job Offer 26\n",
      "Scraping job details: 27 DONE.\n",
      "Scraping the description of Job Offer 27\n",
      "Scraping job details: 28 DONE.\n",
      "Scraping the description of Job Offer 28\n",
      "Scraping job details: 29 DONE.\n",
      "Scraping the description of Job Offer 29\n",
      "Scraping job details: 30 DONE.\n",
      "Scraping the description of Job Offer 30\n",
      "Scraping job details: 31 DONE.\n",
      "Scraping the description of Job Offer 31\n",
      "Scraping job details: 32 DONE.\n",
      "Scraping the description of Job Offer 32\n",
      "Scraping job details: 33 DONE.\n",
      "Scraping the description of Job Offer 33\n",
      "Scraping job details: 34 DONE.\n",
      "Scraping the description of Job Offer 34\n",
      "Scraping job details: 35 DONE.\n",
      "Scraping the description of Job Offer 35\n",
      "Scraping job details: 36 DONE.\n",
      "Scraping the description of Job Offer 36\n",
      "Scraping job details: 37 DONE.\n",
      "Scraping the description of Job Offer 37\n",
      "Scraping job details: 38 DONE.\n",
      "Scraping the description of Job Offer 38\n",
      "Scraping job details: 39 DONE.\n",
      "Scraping the description of Job Offer 39\n",
      "Scraping job details: 40 DONE.\n",
      "Scraping the description of Job Offer 40\n",
      "Scraping job details: 41 DONE.\n",
      "Scraping the description of Job Offer 41\n",
      "Scraping job details: 42 DONE.\n",
      "Scraping the description of Job Offer 42\n",
      "Scraping job details: 43 DONE.\n",
      "Scraping the description of Job Offer 43\n",
      "Scraping job details: 44 DONE.\n",
      "Scraping the description of Job Offer 44\n",
      "Scraping job details: 45 DONE.\n",
      "Scraping the description of Job Offer 45\n",
      "Scraping job details: 46 DONE.\n",
      "Scraping the description of Job Offer 46\n",
      "Scraping job details: 47 DONE.\n",
      "Scraping the description of Job Offer 47\n",
      "Scraping job details: 48 DONE.\n",
      "Scraping the description of Job Offer 48\n",
      "Scraping job details: 49 DONE.\n",
      "Scraping the description of Job Offer 49\n",
      "Scraping job details: 50 DONE.\n",
      "Scraping the description of Job Offer 50\n",
      "Scraping job details: 51 DONE.\n",
      "Scraping the description of Job Offer 51\n",
      "Scraping job details: 52 DONE.\n",
      "Scraping the description of Job Offer 52\n",
      "Scraping job details: 53 DONE.\n",
      "Scraping the description of Job Offer 53\n",
      "Scraping job details: 54 DONE.\n",
      "Scraping the description of Job Offer 54\n",
      "Scraping job details: 55 DONE.\n",
      "Scraping the description of Job Offer 55\n",
      "Scraping job details: 56 DONE.\n",
      "Scraping the description of Job Offer 56\n",
      "Scraping job details: 57 DONE.\n",
      "Scraping the description of Job Offer 57\n",
      "Scraping job details: 58 DONE.\n",
      "Scraping the description of Job Offer 58\n",
      "Scraping job details: 59 DONE.\n",
      "Scraping the description of Job Offer 59\n",
      "Scraping job details: 60 DONE.\n",
      "Scraping the description of Job Offer 60\n",
      "Scraping job details: 61 DONE.\n",
      "Scraping the description of Job Offer 61\n",
      "Scraping job details: 62 DONE.\n",
      "Scraping the description of Job Offer 62\n",
      "Scraping job details: 63 DONE.\n",
      "Scraping the description of Job Offer 63\n",
      "Scraping job details: 64 DONE.\n",
      "Scraping the description of Job Offer 64\n",
      "Scraping job details: 65 DONE.\n",
      "Scraping the description of Job Offer 65\n",
      "Scraping job details: 66 DONE.\n",
      "Scraping the description of Job Offer 66\n",
      "Scraping job details: 67 DONE.\n",
      "Scraping the description of Job Offer 67\n",
      "Scraping job details: 68 DONE.\n",
      "Scraping the description of Job Offer 68\n",
      "Scraping job details: 69 DONE.\n",
      "Scraping the description of Job Offer 69\n",
      "Scraping job details: 70 DONE.\n",
      "Scraping the description of Job Offer 70\n",
      "Scraping job details: 71 DONE.\n",
      "Scraping the description of Job Offer 71\n",
      "Scraping job details: 72 DONE.\n",
      "Scraping the description of Job Offer 72\n",
      "Scraping job details: 73 DONE.\n",
      "Scraping the description of Job Offer 73\n",
      "Scraping job details: 74 DONE.\n",
      "Scraping the description of Job Offer 74\n",
      "Scraping job details: 75 DONE.\n",
      "Scraping the description of Job Offer 75\n",
      "Scraping job details: 76 DONE.\n",
      "Scraping the description of Job Offer 76\n",
      "Scraping job details: 77 DONE.\n",
      "Scraping the description of Job Offer 77\n",
      "Scraping job details: 78 DONE.\n",
      "Scraping the description of Job Offer 78\n",
      "Scraping job details: 79 DONE.\n",
      "Scraping the description of Job Offer 79\n",
      "Scraping job details: 80 DONE.\n",
      "Scraping the description of Job Offer 80\n",
      "Scraping job details: 81 DONE.\n",
      "Scraping the description of Job Offer 81\n",
      "Scraping job details: 82 DONE.\n",
      "Scraping the description of Job Offer 82\n",
      "Scraping job details: 83 DONE.\n",
      "Scraping the description of Job Offer 83\n",
      "Scraping job details: 84 DONE.\n",
      "Scraping the description of Job Offer 84\n",
      "Scraping job details: 85 DONE.\n",
      "Scraping the description of Job Offer 85\n",
      "Scraping job details: 86 DONE.\n",
      "Scraping the description of Job Offer 86\n",
      "Scraping job details: 87 DONE.\n",
      "Scraping the description of Job Offer 87\n",
      "Scraping job details: 88 DONE.\n",
      "Scraping the description of Job Offer 88\n",
      "Scraping job details: 89 DONE.\n",
      "Scraping the description of Job Offer 89\n",
      "Scraping job details: 90 DONE.\n",
      "Scraping the description of Job Offer 90\n",
      "Scraping job details: 91 DONE.\n",
      "Scraping the description of Job Offer 91\n",
      "Scraping job details: 92 DONE.\n",
      "Scraping the description of Job Offer 92\n",
      "Scraping job details: 93 DONE.\n",
      "Scraping the description of Job Offer 93\n",
      "Scraping job details: 94 DONE.\n",
      "Scraping the description of Job Offer 94\n",
      "Scraping job details: 95 DONE.\n",
      "Scraping the description of Job Offer 95\n",
      "Scraping job details: 96 DONE.\n",
      "Scraping the description of Job Offer 96\n",
      "Scraping job details: 97 DONE.\n",
      "Scraping the description of Job Offer 97\n",
      "Scraping job details: 98 DONE.\n",
      "Scraping the description of Job Offer 98\n",
      "Scraping job details: 99 DONE.\n",
      "Scraping the description of Job Offer 99\n",
      "Scraping job details: 100 DONE.\n",
      "Scraping the description of Job Offer 100\n",
      "Scraping job details: 101 DONE.\n",
      "Scraping the description of Job Offer 101\n",
      "Scraping job details: 102 DONE.\n",
      "Scraping the description of Job Offer 102\n",
      "Scraping job details: 103 DONE.\n",
      "Scraping the description of Job Offer 103\n",
      "Scraping job details: 104 DONE.\n",
      "Scraping the description of Job Offer 104\n",
      "Scraping job details: 105 DONE.\n",
      "Scraping the description of Job Offer 105\n",
      "Scraping job details: 106 DONE.\n",
      "Scraping the description of Job Offer 106\n",
      "Scraping job details: 107 DONE.\n",
      "Scraping the description of Job Offer 107\n",
      "Scraping job details: 108 DONE.\n",
      "Scraping the description of Job Offer 108\n",
      "Scraping job details: 109 DONE.\n",
      "Scraping the description of Job Offer 109\n",
      "Scraping job details: 110 DONE.\n",
      "Scraping the description of Job Offer 110\n",
      "Scraping job details: 111 DONE.\n",
      "Scraping the description of Job Offer 111\n",
      "Scraping job details: 112 DONE.\n",
      "Scraping the description of Job Offer 112\n",
      "Scraping job details: 113 DONE.\n",
      "Scraping the description of Job Offer 113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping job details: 114 DONE.\n",
      "Scraping the description of Job Offer 114\n",
      "Scraping job details: 115 DONE.\n",
      "Scraping the description of Job Offer 115\n",
      "Scraping job details: 116 DONE.\n",
      "Scraping the description of Job Offer 116\n",
      "Scraping job details: 117 DONE.\n",
      "Scraping the description of Job Offer 117\n",
      "Scraping job details: 118 DONE.\n",
      "Scraping the description of Job Offer 118\n",
      "Scraping job details: 119 DONE.\n",
      "Scraping the description of Job Offer 119\n",
      "Scraping job details: 120 DONE.\n",
      "Scraping the description of Job Offer 120\n",
      "Scraping job details: 121 DONE.\n",
      "Scraping the description of Job Offer 121\n",
      "Scraping job details: 122 DONE.\n",
      "Scraping the description of Job Offer 122\n",
      "Scraping job details: 123 DONE.\n",
      "Scraping the description of Job Offer 123\n",
      "Scraping job details: 124 DONE.\n",
      "Scraping the description of Job Offer 124\n",
      "Scraping job details: 125 DONE.\n",
      "Scraping the description of Job Offer 125\n",
      "Scraping job details: 126 DONE.\n",
      "Scraping the description of Job Offer 126\n",
      "Scraping job details: 127 DONE.\n",
      "Scraping the description of Job Offer 127\n",
      "Scraping job details: 128 DONE.\n",
      "Scraping the description of Job Offer 128\n",
      "Scraping job details: 129 DONE.\n",
      "Scraping the description of Job Offer 129\n",
      "Scraping job details: 130 DONE.\n",
      "Scraping the description of Job Offer 130\n",
      "Scraping job details: 131 DONE.\n",
      "Scraping the description of Job Offer 131\n",
      "Scraping job details: 132 DONE.\n",
      "Scraping the description of Job Offer 132\n",
      "Scraping job details: 133 DONE.\n",
      "Scraping the description of Job Offer 133\n",
      "Scraping job details: 134 DONE.\n",
      "Scraping the description of Job Offer 134\n",
      "Scraping job details: 135 DONE.\n",
      "Scraping the description of Job Offer 135\n",
      "Scraping job details: 136 DONE.\n",
      "Scraping the description of Job Offer 136\n",
      "Scraping job details: 137 DONE.\n",
      "Scraping the description of Job Offer 137\n",
      "Scraping job details: 138 DONE.\n",
      "Scraping the description of Job Offer 138\n",
      "Scraping job details: 139 DONE.\n",
      "Scraping the description of Job Offer 139\n",
      "Scraping job details: 140 DONE.\n",
      "Scraping the description of Job Offer 140\n",
      "Scraping job details: 141 DONE.\n",
      "Scraping the description of Job Offer 141\n",
      "Scraping job details: 142 DONE.\n",
      "Scraping the description of Job Offer 142\n",
      "Scraping job details: 143 DONE.\n",
      "Scraping the description of Job Offer 143\n",
      "Scraping job details: 144 DONE.\n",
      "Scraping the description of Job Offer 144\n",
      "Scraping job details: 145 DONE.\n",
      "Scraping the description of Job Offer 145\n",
      "Scraping job details: 146 DONE.\n",
      "Scraping the description of Job Offer 146\n",
      "Scraping job details: 147 DONE.\n",
      "Scraping the description of Job Offer 147\n",
      "Scraping job details: 148 DONE.\n",
      "Scraping the description of Job Offer 148\n",
      "Scraping job details: 149 DONE.\n",
      "Scraping the description of Job Offer 149\n",
      "Scraping job details: 150 DONE.\n",
      "Scraping the description of Job Offer 150\n",
      "                                               Company  \\\n",
      "0                                                IBMMQ   \n",
      "1                                                Appen   \n",
      "2                                            Scientiae   \n",
      "3    Société Générale - Africa Technologies & Services   \n",
      "4                                     Société Générale   \n",
      "..                                                 ...   \n",
      "145                                                CGI   \n",
      "146                                                CGI   \n",
      "147                                              Agoda   \n",
      "148                                 GlobalLogic Poland   \n",
      "149                                                CGI   \n",
      "\n",
      "                                             Job Title          Post Date  \\\n",
      "0                            Développeur Oracle PL/SQL   il y a 11 heures   \n",
      "1               Data Collection Analyst Arabic Speaker   il y a 18 heures   \n",
      "2                                             Analyste   il y a 1 semaine   \n",
      "3    Operational Risk Management – Operational Prod...   il y a 14 heures   \n",
      "4                                   DATA ANALYST-(H/F)      il y a 1 mois   \n",
      "..                                                 ...                ...   \n",
      "145                Directeur Consulting Delivery (H/F)     il y a 4 jours   \n",
      "146                Consultant sénior SAP BW/ABAP (H/F)  il y a 2 semaines   \n",
      "147  Marketing Analyst (Bangkok Based, Relocation P...     il y a 6 jours   \n",
      "148  Mid/Senior AUTOSAR Adaptive Engineer (Relocati...  il y a 2 semaines   \n",
      "149                Consultant sénior SAP BW/ABAP (H/F)  il y a 2 semaines   \n",
      "\n",
      "                                 Location  \\\n",
      "0                Casablanca et périphérie   \n",
      "1                    Meknès et périphérie   \n",
      "2        Rabat, Rabat-Salé-Kénitra, Maroc   \n",
      "3    Casablanca, Casablanca-Settat, Maroc   \n",
      "4                                   Maroc   \n",
      "..                                    ...   \n",
      "145                Fès, Fès-Meknès, Maroc   \n",
      "146      Rabat, Rabat-Salé-Kénitra, Maroc   \n",
      "147      Marrakech, Marrakech-Safi, Maroc   \n",
      "148                                 Maroc   \n",
      "149      Rabat, Rabat-Salé-Kénitra, Maroc   \n",
      "\n",
      "                                              Job Link  \\\n",
      "0    https://www.linkedin.com/jobs/view/3617574620/...   \n",
      "1    https://www.linkedin.com/jobs/view/3611144486/...   \n",
      "2    https://www.linkedin.com/jobs/view/3610335537/...   \n",
      "3    https://www.linkedin.com/jobs/view/3615072217/...   \n",
      "4    https://www.linkedin.com/jobs/view/3609908340/...   \n",
      "..                                                 ...   \n",
      "145  https://www.linkedin.com/jobs/view/3611649995/...   \n",
      "146  https://www.linkedin.com/jobs/view/3602319572/...   \n",
      "147  https://www.linkedin.com/jobs/view/3610210846/...   \n",
      "148  https://www.linkedin.com/jobs/view/3563644736/...   \n",
      "149  https://www.linkedin.com/jobs/view/3602968048/...   \n",
      "\n",
      "                                       Job Description  \n",
      "0    À propos de l’offre d’emploi\\nNous sommes à la...  \n",
      "1    À propos de l’offre d’emploi\\nData Collection ...  \n",
      "2    À propos de l’offre d’emploi\\nEntreprise\\nScie...  \n",
      "3    À propos de l’offre d’emploi\\nMissions\\nDans l...  \n",
      "4    À propos de l’offre d’emploi\\nVos missions au ...  \n",
      "..                                                 ...  \n",
      "145  À propos de l’offre d’emploi\\nRattaché(e) au D...  \n",
      "146  À propos de l’offre d’emploi\\nNous recherchons...  \n",
      "147  À propos de l’offre d’emploi\\nAbout Agoda\\n\\nA...  \n",
      "148  À propos de l’offre d’emploi\\nIn GlobalLogic w...  \n",
      "149  À propos de l’offre d’emploi\\nDescription de p...  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "job_titles = []\n",
    "company_names = []\n",
    "company_locations = []\n",
    "post_dates = []\n",
    "job_desc = []\n",
    "job_links = []\n",
    "\n",
    "\n",
    "\n",
    "j = 1\n",
    "\n",
    "# Visit each link one by one to scrape the information\n",
    "print('Visiting the links and collecting information...')\n",
    "for link in links:\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        time.sleep(2)\n",
    "        # Click See more if available.\n",
    "        see_more_button = driver.find_elements(By.XPATH, '//*[@id=\"ember33\"]')\n",
    "        see_more_button[0].click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Find the general information of the job offers\n",
    "    contents = driver.find_elements(By.CLASS_NAME, \"p5\")\n",
    "    for content in contents:\n",
    "        try:\n",
    "            job_titles.append(content.find_element(By.CSS_SELECTOR, \"h1\").text)\n",
    "            company_names.append(content.find_element(By.CSS_SELECTOR, \".jobs-unified-top-card__company-name\").text)\n",
    "            company_locations.append(content.find_element(By.CSS_SELECTOR, \".jobs-unified-top-card__bullet\").text)\n",
    "            post_dates.append(content.find_element(By.CSS_SELECTOR, \".jobs-unified-top-card__posted-date\").text)\n",
    "            print(f'Scraping job details: {j} DONE.')\n",
    "\n",
    "            # Scraping the job description\n",
    "            job_description = driver.find_elements(By.CLASS_NAME, \"jobs-description__content\")\n",
    "            for description in job_description:\n",
    "                job_text = description.text\n",
    "                job_desc.append(job_text)\n",
    "                job_links.append(link)\n",
    "                print(f'Scraping the description of Job Offer {j}')\n",
    "                time.sleep(2)\n",
    "\n",
    "            j += 1\n",
    "            time.sleep(2)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# Create separate DataFrames for each column of data\n",
    "company_df = pd.DataFrame(company_names, columns=[\"Company\"])\n",
    "title_df = pd.DataFrame(job_titles, columns=[\"Job Title\"])\n",
    "date_df = pd.DataFrame(post_dates, columns=[\"Post Date\"])\n",
    "localisation_df = pd.DataFrame(company_locations, columns=[\"Location\"])\n",
    "description_df = pd.DataFrame(job_desc, columns=[\"Job Description\"])\n",
    "link_df = pd.DataFrame(job_links, columns=[\"Job Link\"])\n",
    "\n",
    "# Join the DataFrames into a single DataFrame\n",
    "result_df = pd.concat([company_df, title_df, date_df, localisation_df,link_df, description_df], axis=1)\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9468662",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8072\\398037041.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result_df' is not defined"
     ]
    }
   ],
   "source": [
    "result_df.to_excel('result.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c7543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f20cf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119e4ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfa34581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_phrases_with_words(text, words):\n",
    "    pattern = r\"(.*?[.!?])\"\n",
    "    phrases = []\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "    \n",
    "    for match in matches:\n",
    "        if any(re.search(r\"\\b\" + re.escape(word) + r\"\\b\", match, re.IGNORECASE) for word in words):\n",
    "            phrases.append(match.strip())\n",
    "    \n",
    "    return phrases\n",
    "\n",
    "def extract_words(text, words):\n",
    "    words_found = []\n",
    "    \n",
    "    for word in words:\n",
    "        if re.search(r\"\\b\" + re.escape(word) + r\"\\b\", text, re.IGNORECASE):\n",
    "            words_found.append(word)\n",
    "    \n",
    "    return words_found\n",
    "\n",
    "# Charger le fichier Excel\n",
    "data_frame = pd.read_excel('C:\\\\Users\\\\pc\\\\Desktop\\\\finalresult.xlsx')\n",
    "\n",
    "# Nom de la feuille de calcul à utiliser\n",
    "nom_feuille = 'Sheet1'\n",
    "\n",
    "# Colonnes à parcourir dans le fichier Excel\n",
    "colonnes = ['Job Description']\n",
    "\n",
    "# Parcourir chaque ligne du fichier Excel\n",
    "for index, row in data_frame.iterrows():\n",
    "    traitement_phrases1 = ''\n",
    "    traitement_phrases2 = ''\n",
    "    traitement_sql = ''\n",
    "    traitement_MySql = ''\n",
    "    traitement_PostgreSql = ''\n",
    "    traitement_SqlServer = ''\n",
    "    traitement_PowerBI = ''\n",
    "    traitement_tableau = ''\n",
    "    traitement_Qlik = ''\n",
    "    traitement_BigData = ''\n",
    "    traitement_Cloudera = ''\n",
    "    traitement_hive = ''\n",
    "    traitement_Pyspark = ''\n",
    "    traitement_Impala = ''\n",
    "    traitement_DataScience = ''\n",
    "    traitement_Dataiku = ''\n",
    "    traitement_Knime = ''\n",
    "    traitement_IBMSPSS = ''\n",
    "    traitement_ETL = ''\n",
    "    traitement_Talend = ''\n",
    "    traitement_Informatica = ''\n",
    "    traitement_SSIS = ''\n",
    "    traitement_DataAnalytics = ''\n",
    "    traitement_python = ''\n",
    "    traitement_Pandas = ''\n",
    "    traitement_NumPy = ''\n",
    "    traitement_R = ''\n",
    "    traitement_java = ''\n",
    "    traitement_C = ''\n",
    "    traitement_C_plus = ''\n",
    "    traitement_java_avance = ''\n",
    "    \n",
    "    for colonne in colonnes:\n",
    "        cellule = str(row[colonne])\n",
    "        phrases_francais_anglais = extract_phrases_with_words(cellule, ['français', 'anglais'])\n",
    "        phrase_etu = extract_phrases_with_words(cellule, ['école', 'bac+'])\n",
    "        mots_sql = extract_words(cellule, ['SQL'])\n",
    "        mots_MySQL = extract_words(cellule, ['MySQL'])\n",
    "        mots_PostgreSql = extract_words(cellule, ['PostgreSql'])\n",
    "        mots_SqlServer = extract_words(cellule, ['SQL Server'])\n",
    "        mots_PowerBI = extract_words(cellule, ['Power BI'])\n",
    "        mots_tableau = extract_words(cellule, ['tableau'])\n",
    "        mots_Qlik = extract_words(cellule, ['Qlik'])\n",
    "        mots_BigData = extract_words(cellule, ['Big Data'])\n",
    "        mots_Cloudera = extract_words(cellule, ['Cloudera'])\n",
    "        mots_hive = extract_words(cellule, ['hive'])\n",
    "        mots_Pyspark = extract_words(cellule, ['Pyspark'])\n",
    "        mots_Impala = extract_words(cellule, ['Impala'])\n",
    "        mots_DataScience = extract_words(cellule, ['Data Science'])\n",
    "        mots_Dataiku = extract_words(cellule, ['Dataiku'])\n",
    "        mots_Knime = extract_words(cellule, ['Knime'])\n",
    "        mots_IBMSPSS = extract_words(cellule, ['IBM SPSS'])\n",
    "        mots_ETL = extract_words(cellule, ['ETL'])\n",
    "        mots_Talend = extract_words(cellule, ['Talend'])\n",
    "        mots_Informatica = extract_words(cellule, ['Informatica'])\n",
    "        mots_SSIS = extract_words(cellule, ['SSIS'])\n",
    "        mots_DataAnalytics = extract_words(cellule, ['Data analytics'])\n",
    "        mots_python = extract_words(cellule, ['python'])\n",
    "        mots_Pandas = extract_words(cellule, ['Pandas'])\n",
    "        mots_NumPy = extract_words(cellule, ['NumPy'])\n",
    "        mots_R = extract_words(cellule, ['R'])\n",
    "        mots_java = extract_words(cellule, ['java'])\n",
    "        mots_C = extract_words(cellule, ['C'])\n",
    "        mots_C_plus = extract_words(cellule, ['C++'])\n",
    "        mots_java_avance = extract_words(cellule, ['java avancé'])\n",
    "        \n",
    "        if phrases_francais_anglais:\n",
    "            traitement_phrases1 += ' '.join(phrases_francais_anglais) + ' '\n",
    "        \n",
    "        if phrase_etu:\n",
    "            traitement_phrases2 += ' '.join(phrase_etu) + ' '\n",
    "        \n",
    "        if mots_sql:\n",
    "            traitement_sql += ' '.join(mots_sql) + ' '\n",
    "        \n",
    "        if mots_MySQL:\n",
    "            traitement_MySql += ' '.join(mots_MySQL) + ' '\n",
    "        \n",
    "        if mots_PostgreSql:\n",
    "            traitement_PostgreSql += ' '.join(mots_PostgreSql) + ' '\n",
    "        \n",
    "        if mots_SqlServer:\n",
    "            traitement_SqlServer += ' '.join(mots_SqlServer) + ' '\n",
    "        \n",
    "        if mots_PowerBI:\n",
    "            traitement_PowerBI += ' '.join(mots_PowerBI) + ' '\n",
    "        \n",
    "        if mots_tableau:\n",
    "            traitement_tableau += ' '.join(mots_tableau) + ' '\n",
    "        \n",
    "        if mots_Qlik:\n",
    "            traitement_Qlik += ' '.join(mots_Qlik) + ' '\n",
    "        \n",
    "        if mots_BigData:\n",
    "            traitement_BigData += ' '.join(mots_BigData) + ' '\n",
    "        \n",
    "        if mots_Cloudera:\n",
    "            traitement_Cloudera += ' '.join(mots_Cloudera) + ' '\n",
    "        \n",
    "        if mots_hive:\n",
    "            traitement_hive += ' '.join(mots_hive) + ' '\n",
    "        \n",
    "        if mots_Pyspark:\n",
    "            traitement_Pyspark += ' '.join(mots_Pyspark) + ' '\n",
    "        \n",
    "        if mots_Impala:\n",
    "            traitement_Impala += ' '.join(mots_Impala) + ' '\n",
    "        \n",
    "        if mots_DataScience:\n",
    "            traitement_DataScience += ' '.join(mots_DataScience) + ' '\n",
    "        \n",
    "        if mots_Dataiku:\n",
    "            traitement_Dataiku += ' '.join(mots_Dataiku) + ' '\n",
    "        \n",
    "        if mots_Knime:\n",
    "            traitement_Knime += ' '.join(mots_Knime) + ' '\n",
    "        \n",
    "        if mots_IBMSPSS:\n",
    "            traitement_IBMSPSS += ' '.join(mots_IBMSPSS) + ' '\n",
    "        \n",
    "        if mots_ETL:\n",
    "            traitement_ETL += ' '.join(mots_ETL) + ' '\n",
    "        \n",
    "        if mots_Talend:\n",
    "            traitement_Talend += ' '.join(mots_Talend) + ' '\n",
    "        \n",
    "        if mots_Informatica:\n",
    "            traitement_Informatica += ' '.join(mots_Informatica) + ' '\n",
    "        \n",
    "        if mots_SSIS:\n",
    "            traitement_SSIS += ' '.join(mots_SSIS) + ' '\n",
    "        \n",
    "        if mots_DataAnalytics:\n",
    "            traitement_DataAnalytics += ' '.join(mots_DataAnalytics) + ' '\n",
    "        \n",
    "        if mots_python:\n",
    "            traitement_python += ' '.join(mots_python) + ' '\n",
    "        \n",
    "        if mots_Pandas:\n",
    "            traitement_Pandas += ' '.join(mots_Pandas) + ' '\n",
    "        \n",
    "        if mots_NumPy:\n",
    "            traitement_NumPy += ' '.join(mots_NumPy) + ' '\n",
    "        \n",
    "        if mots_R:\n",
    "            traitement_R += ' '.join(mots_R) + ' '\n",
    "        \n",
    "        if mots_java:\n",
    "            traitement_java += ' '.join(mots_java) + ' '\n",
    "        \n",
    "        if mots_C:\n",
    "            traitement_C += ' '.join(mots_C) + ' '\n",
    "        \n",
    "        if mots_C_plus:\n",
    "            traitement_C_plus += ' '.join(mots_C_plus) + ' '\n",
    "        \n",
    "        if mots_java_avance:\n",
    "            traitement_java_avance += ' '.join(mots_java_avance) + ' '\n",
    "\n",
    "    # Enregistrer le traitement dans la colonne \"Traitement\"\n",
    "    data_frame.at[index, 'langue'] = traitement_phrases1\n",
    "    data_frame.at[index, 'diplome'] = traitement_phrases2\n",
    "    data_frame.at[index, 'SQL'] = traitement_sql\n",
    "    data_frame.at[index, 'MySQL'] = traitement_MySql\n",
    "    data_frame.at[index, 'PostgreSql'] = traitement_PostgreSql\n",
    "    data_frame.at[index, 'SQL Server'] = traitement_SqlServer\n",
    "    data_frame.at[index, 'Power BI'] = traitement_PowerBI\n",
    "    data_frame.at[index, 'tableau'] = traitement_tableau\n",
    "    data_frame.at[index, 'Qlik'] = traitement_Qlik\n",
    "    data_frame.at[index, 'Big Data'] = traitement_BigData\n",
    "    data_frame.at[index, 'Cloudera'] = traitement_Cloudera\n",
    "    data_frame.at[index, 'hive'] = traitement_hive\n",
    "    data_frame.at[index, 'Pyspark'] = traitement_Pyspark\n",
    "    data_frame.at[index, 'Impala'] = traitement_Impala\n",
    "    data_frame.at[index, 'Data Science'] = traitement_DataScience\n",
    "    data_frame.at[index, 'Dataiku'] = traitement_Dataiku\n",
    "    data_frame.at[index, 'Knime'] = traitement_Knime\n",
    "    data_frame.at[index, 'IBM SPSS'] = traitement_IBMSPSS\n",
    "    data_frame.at[index, 'ETL'] = traitement_ETL\n",
    "    data_frame.at[index, 'Talend'] = traitement_Talend\n",
    "    data_frame.at[index, 'Informatica'] = traitement_Informatica\n",
    "    data_frame.at[index, 'SSIS'] = traitement_SSIS\n",
    "    data_frame.at[index, 'Data analytics'] = traitement_DataAnalytics\n",
    "    data_frame.at[index, 'python'] = traitement_python\n",
    "    data_frame.at[index, 'Pandas'] = traitement_Pandas\n",
    "    data_frame.at[index, 'NumPy'] = traitement_NumPy\n",
    "    data_frame.at[index, 'R'] = traitement_R\n",
    "    data_frame.at[index, 'java'] = traitement_java\n",
    "    data_frame.at[index, 'C'] = traitement_C\n",
    "    data_frame.at[index, 'C++'] = traitement_C_plus\n",
    "    data_frame.at[index, 'java avancé'] = traitement_java_avance\n",
    "\n",
    "# Enregistrer les modifications dans le fichier Excel\n",
    "data_frame.to_excel('C:\\\\Users\\\\pc\\\\Desktop\\\\finalresult.xlsx', index=False, sheet_name=nom_feuille)\n",
    "\n",
    "\n",
    "\n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcbfc18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd90d5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acc887d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import locale\n",
    "import re\n",
    "\n",
    "# Lecture du fichier Excel\n",
    "df = pd.read_excel(r\"C:\\Users\\pc\\Desktop\\PFA\\sheets\\jobs\\result.xlsx\")\n",
    "\n",
    "# Nom de la colonne contenant les informations de durée\n",
    "colonne_duree = \"Post Date\"\n",
    "\n",
    "# Configuration des paramètres régionaux pour le format de date\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "\n",
    "# Date ultérieure donnée\n",
    "date_ulterieure = datetime(2023, 5, 30, 23, 23, 55)\n",
    "\n",
    "# Fonction pour convertir la durée en date de publication par rapport à la date ultérieure\n",
    "def convertir_duree_en_date(duree):\n",
    "    if duree is None or pd.isnull(duree):\n",
    "        return None\n",
    "\n",
    "    if isinstance(duree, str):\n",
    "        match = re.search(r\"il y a (\\d+) (\\w+)\", duree)\n",
    "        if match:\n",
    "            quantite = int(match.group(1))\n",
    "            unite = match.group(2)\n",
    "\n",
    "            if unite == \"heure\" or unite == \"heures\":\n",
    "                date_publication = date_ulterieure - timedelta(hours=quantite)\n",
    "            elif unite == \"semaine\" or unite == \"semaines\":\n",
    "                date_publication = date_ulterieure - timedelta(weeks=quantite)\n",
    "            elif unite == \"mois\":\n",
    "                date_publication = date_ulterieure - timedelta(days=30 * quantite)\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "            return date_publication.strftime(\"%A %d %B %Y, %H:%M:%S\")\n",
    "\n",
    "    return None\n",
    "\n",
    "# Conversion des durées en dates de publication\n",
    "df[\"Date de publication\"] = df[colonne_duree].apply(lambda x: convertir_duree_en_date(x) if x is not None and not pd.isnull(x) else None)\n",
    "\n",
    "# Affichage du dataframe avec la nouvelle colonne de dates de publication\n",
    "df.to_excel(\"result-date-trait.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36b9f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lecture du fichier Excel\n",
    "df = pd.read_excel(r\"C:\\Users\\pc\\Desktop\\PFA\\sheets\\jobs\\result-date-trait.xlsx\")\n",
    "\n",
    "# Traitement de la colonne \"Location\"\n",
    "df.loc[df[\"Location\"].str.contains(\"casablanca\", case=False), \"Location\"] = \"Casablanca et périphérie\"\n",
    "df.loc[df[\"Location\"].str.contains(\"rabat\", case=False), \"Location\"] = \"Rabat et périphérie\"\n",
    "\n",
    "# Enregistrement du dataframe dans un fichier Excel\n",
    "df.to_excel(\"result-loc-trait.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3e947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mots_cles = [\"Python\", \"Pandas\", \"Numpy\",\"Beautiful soup\",\"Selenium\", \"SQL Server\", \"PostgreSql\", \"MySQL\", \"SQL\", \"NO SQL\", \"PL/SQL\", \"Linux\", \"SGBD\",\n",
    "             \"Git\", \"Qlik\", \"tableau\", \"Power BI\", \"Power Query\", \"Latex\", \"Qlick view\", \"Cloudera\", \"TenserFlow\",\"SAP\",\"SSIS\"\n",
    "             \"OpenCv\", \"Matlab\", \"Apache\", \"Jira\", \"C++\", \"JAVA\", \"java\", \"Merise\", \"HTML\", \"CSS\", \"Laravel\",\"PHP\",\"Pyspark\",\"ETL\",\"Dataiku\",\n",
    "             \"Jquerry\", \"UML\", \"Data analytics\", \"Statistics\", \"Problem Solving\", \"Web Scraping\", \"Data Modeling\",\"Knime\",\"Impala\",\"e-commerce\"\n",
    "             \"Artificial Intelligence\", \"Data Engineering\", \"Data Analytics\", \"Data Warehouse\", \"Applied Mathematics\",\"datamining\",\n",
    "             \"Big Data\", \"Data Visualisation\", \"Business Intelligence\", \"Machine Learning\", \"ERP\",\"ANAPLAN\", \"CRM\", \"GRH\", \"PMO\" , \"Microsoft Excel\"]\n",
    "\n",
    "def extract_keywords(text):\n",
    "    keywords = []\n",
    "    for mot_cle in mots_cles:\n",
    "        if mot_cle.lower() in text.lower():\n",
    "            keywords.append(mot_cle)\n",
    "    return \", \".join(keywords)\n",
    "\n",
    "# Lire le fichier Excel\n",
    "df = pd.read_excel( r\"C:\\Users\\pc\\Desktop\\PFA\\sheets\\jobs\\result-loc-trait.xlsx\")\n",
    "\n",
    "# Appliquer la fonction extract_keywords pour créer la colonne \"compétences\"\n",
    "df[\"compétences\"] = df[\"Job Description\"].apply(extract_keywords)\n",
    "\n",
    "# Enregistrer le DataFrame modifié dans un nouveau fichier Excel\n",
    "df.to_excel(\"CASE-VIDE.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acead423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
